{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import re\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms as T\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Load mask rcnn model\n",
    "def get_model(num_classes):\n",
    "    pretrained_base_model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
    "    # print(pretrained_base_model)\n",
    "\n",
    "    in_features = pretrained_base_model.roi_heads.box_predictor.cls_score.in_features\n",
    "    pretrained_base_model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    mask_in_channels = pretrained_base_model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "    pretrained_base_model.roi_heads.mask_predictor = MaskRCNNPredictor(mask_in_channels, 256, num_classes)\n",
    "    return pretrained_base_model\n",
    "\n",
    "num_classes = 2  # the background class and the pedestrian class\n",
    "maskrcnn = get_model(num_classes)\n",
    "device = torch.device('cpu')\n",
    "maskrcnn = torch.load(\"maskrcnn.pth\", map_location=device)\n",
    "maskrcnn = maskrcnn.to(device)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Load faster rcnn model\n",
    "fasterrcnn = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "in_features = fasterrcnn.roi_heads.box_predictor.cls_score.in_features\n",
    "fasterrcnn.roi_heads.box_predictor = FastRCNNPredictor(in_features, 2)\n",
    "fasterrcnn.load_state_dict(torch.load(\"fasterrcnn_phase1.pth\", map_location=device))\n",
    "fasterrcnn = fasterrcnn.to(device)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YOLO model\n",
    "from ultralytics import YOLO\n",
    "model_detection = YOLO('detect.pt')\n",
    "model_segmentation = YOLO('segment.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate YOLO Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_detect(input_directory, output_directory='output', detection_threshold=0.5):\n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "    # Create \"Count\" folder in the output directory\n",
    "    count_folder = os.path.join(output_directory, 'Count')\n",
    "    os.makedirs(count_folder, exist_ok=True)\n",
    "\n",
    "    bbox_path = os.path.join(output_directory, 'detection')\n",
    "    os.makedirs(bbox_path, exist_ok=True)\n",
    "\n",
    "    roi_folder = os.path.join(output_directory, 'ROI')\n",
    "    os.makedirs(roi_folder, exist_ok=True)\n",
    "    \n",
    "    # List all image files in the input directory\n",
    "    image_files = [f for f in os.listdir(input_directory) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))]\n",
    "\n",
    "    for image_file in image_files:\n",
    "        img_id = image_file.split('.')[0]\n",
    "        image_path = os.path.join(input_directory, image_file)\n",
    "        img = cv2.imread(image_path)\n",
    "        img_copy = copy.deepcopy(img)\n",
    "        results = model_detection(img, conf=detection_threshold)\n",
    "        for r in results:\n",
    "            bbox_list = r.boxes.xyxy\n",
    "            count = len(bbox_list)  \n",
    "            for i, bbox in enumerate(bbox_list):\n",
    "                # Extract ROI\n",
    "                roi = img_copy[int(bbox[1]):int(bbox[3]), int(bbox[0]):int(bbox[2])]\n",
    "                # Save ROI\n",
    "                roi_path = os.path.join(roi_folder, f'{img_id}_{i+1}.jpg')\n",
    "                cv2.imwrite(roi_path, roi)\n",
    "                img_detect = cv2.rectangle(img, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), (0, 0, 255), 5)\n",
    "\n",
    "            # Save image with bounding boxes\n",
    "            detect_path = os.path.join(bbox_path, f'{img_id}_with_boxes.jpg')\n",
    "            cv2.imwrite(detect_path, img_detect)\n",
    "\n",
    "        # Save count\n",
    "        count_filepath = os.path.join(count_folder, f'{img_id}.txt')\n",
    "        with open(count_filepath, 'w') as f:\n",
    "            f.write(str(count))\n",
    "\n",
    "yolo_detect('input')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Faster RCNN Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Generate faster RCNN prediction\n",
    "def predict(model, images):\n",
    "    model.eval()\n",
    "    images = list(image.to(device) for image in images)\n",
    "    outputs = model(images)\n",
    "    return outputs\n",
    "\n",
    "# Draw bounding box on processed image (1024x1024)\n",
    "def draw_boxes_on_image(boxes, images):\n",
    "    for box in boxes:\n",
    "        cv2.rectangle(images,\n",
    "                      (box[0], box[1]),\n",
    "                      (box[2], box[3]),\n",
    "                      (220, 0, 0), 3)\n",
    "    return images\n",
    "\n",
    "# Extract maize tassel image from bounding box\n",
    "def extract_roi(img, img_id, boxes, output_directory):\n",
    "    roi_folder = os.path.join(output_directory, 'ROI')\n",
    "    os.makedirs(roi_folder, exist_ok=True)\n",
    "    for i, box in enumerate(boxes):\n",
    "        x1 = box[0]\n",
    "        y1 = box[1]\n",
    "        x2 = box[2]\n",
    "        y2 = box[3]\n",
    "        # Extract the region of interest (ROI)\n",
    "        roi = img[y1:y2, x1:x2]\n",
    "\n",
    "        # Save the ROI\n",
    "        output_path = os.path.join(roi_folder, f'{img_id}_{i+1}.jpg')\n",
    "        cv2.imwrite(output_path, roi)\n",
    "\n",
    "# Resize bounding box coordinates to original image size\n",
    "def resize_bbox(original_width, original_height, boxes):\n",
    "    for box in boxes:\n",
    "\n",
    "        # Extract coordinates\n",
    "        x1 = box[0]\n",
    "        y1 = box[1]\n",
    "        x2 = box[2]\n",
    "        y2 = box[3]\n",
    "\n",
    "        # Calculate scale factor\n",
    "        width_scale = original_width / 1024\n",
    "        height_scale = original_height / 1024\n",
    "\n",
    "        # Calculate new coordinates\n",
    "        resized_x1 = int(x1 * width_scale)\n",
    "        resized_y1 = int(y1 * height_scale)\n",
    "        resized_x2 = int(x2 * width_scale)\n",
    "        resized_y2 = int(y2 * height_scale)\n",
    "\n",
    "        # Assign new coordinates\n",
    "        box[0] = resized_x1\n",
    "        box[1] = resized_y1\n",
    "        box[2] = resized_x2\n",
    "        box[3] = resized_y2\n",
    "        \n",
    "    return boxes\n",
    "\n",
    "# faster rcnn inference\n",
    "def process_images_and_predict(input_directory, output_directory='output', detection_threshold=0.6):\n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "    # Create \"Count\" folder in the output directory\n",
    "    count_folder = os.path.join(output_directory, 'Count')\n",
    "    os.makedirs(count_folder, exist_ok=True)\n",
    "\n",
    "    # List all image files in the input directory\n",
    "    image_files = [f for f in os.listdir(input_directory) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))]\n",
    "\n",
    "    for img_name in image_files:\n",
    "        \n",
    "        # Read and preprocess image\n",
    "        img_id = img_name.split('.')[0]\n",
    "        image_path = os.path.join(input_directory, img_name)\n",
    "        img = cv2.imread(image_path)\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        img_res = cv2.resize(img_rgb, (1024, 1024), cv2.INTER_AREA)\n",
    "        img_res /= 255.0\n",
    "\n",
    "        # Generate Faster RCNN prediction\n",
    "        output = predict(fasterrcnn, [torch.tensor(img_res, dtype=torch.float32).permute(2, 0, 1).to(device)])\n",
    "        prediction_boxes = output[0]['boxes'].data.cpu().numpy()\n",
    "        scores = output[0]['scores'].data.cpu().numpy()\n",
    "        count = len(prediction_boxes)\n",
    "        # Filter boxes based on detection threshold\n",
    "        prediction_boxes = prediction_boxes[scores >= detection_threshold].astype(np.int32)\n",
    "\n",
    "        # Resize bounding boxes to original image size\n",
    "        prediction_boxes_resized = resize_bbox(img.shape[1], img.shape[0], prediction_boxes)\n",
    "\n",
    "        # Draw bounding box on image and save\n",
    "        img_with_boxes = draw_boxes_on_image(prediction_boxes_resized, img_rgb)\n",
    "        bbox_path = os.path.join(output_directory, 'detection')\n",
    "        os.makedirs(bbox_path, exist_ok=True)\n",
    "        output_path = os.path.join(bbox_path, f'{img_id}_with_boxes.jpg')\n",
    "        cv2.imwrite(output_path, cv2.cvtColor(img_with_boxes, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        # Run extract ROI for image\n",
    "        extract_roi(img, img_id, prediction_boxes_resized, output_directory)\n",
    "\n",
    "        # Save count to text file in \"Count\" folder\n",
    "        count_filepath = os.path.join(count_folder, f'{img_id}.txt')\n",
    "        with open(count_filepath, 'w') as f:\n",
    "            f.write(str(count))\n",
    "\n",
    "# Call the function with the input directory\n",
    "input_directory = 'input'\n",
    "process_images_and_predict(input_directory)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Mask RCNN Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from skimage.feature import graycomatrix\n",
    "from skimage.measure import shannon_entropy\n",
    "from skimage import io, color, util\n",
    "\n",
    "def min_max_normalize_hu_moments(hu_moments):\n",
    "    # Perform min-max normalization for a list of Hu moments\n",
    "    min_value = min(hu_moments)\n",
    "    max_value = max(hu_moments)\n",
    "\n",
    "    normalized_hu_moments = [(value - min_value) / (max_value - min_value) for value in hu_moments]\n",
    "\n",
    "    return normalized_hu_moments\n",
    "\n",
    "# Color outliers\n",
    "def detect_outliers(data, col_indices, lower_bound_multipliers, upper_bound_multipliers):\n",
    "    outliers = np.zeros(len(data), dtype=bool)\n",
    "\n",
    "    for col_index, lower_multiplier, upper_multiplier in zip(col_indices, lower_bound_multipliers, upper_bound_multipliers):\n",
    "        q1 = np.percentile(data[:, col_index], 25)\n",
    "        q3 = np.percentile(data[:, col_index], 75)\n",
    "        iqr = q3 - q1\n",
    "        lower_bound = q1 - lower_multiplier * iqr\n",
    "        upper_bound = q3 + upper_multiplier * iqr\n",
    "\n",
    "        if col_index == 2:\n",
    "            # Skip upper bound comparison for data[:, 2]\n",
    "            outliers_col = (data[:, col_index] < lower_bound)\n",
    "        else:\n",
    "            # Perform both lower and upper bound comparisons for other columns\n",
    "            outliers_col = (data[:, col_index] < lower_bound) | (data[:, col_index] > upper_bound)\n",
    "\n",
    "        outliers |= outliers_col\n",
    "\n",
    "    return outliers\n",
    "\n",
    "# Shape outliers\n",
    "def find_outliers_combined_iqr(hu_moments_list):\n",
    "    outliers = np.zeros(len(hu_moments_list), dtype=bool)\n",
    "    # Calculate the Interquartile Range (IQR)\n",
    "    q1 = np.percentile(hu_moments_list, 25)\n",
    "    q3 = np.percentile(hu_moments_list, 75)\n",
    "    iqr_value = q3 - q1\n",
    "\n",
    "    # Define a multiplier to determine the outlier threshold\n",
    "    iqr_multiplier = 1.5 \n",
    "\n",
    "    # Define the lower and upper bounds for outliers\n",
    "    lower_bound = q1 - iqr_multiplier * iqr_value\n",
    "    upper_bound = q3 + iqr_multiplier * iqr_value\n",
    "\n",
    "    # Identify outliers based on the bounds\n",
    "    outliers_col = (hu_moments_list < lower_bound) | (hu_moments_list > upper_bound)\n",
    "    outliers |= outliers_col\n",
    "\n",
    "    return outliers\n",
    "\n",
    "def process_images_in_directory(input_directory, model, device):\n",
    "\n",
    "    # Get dominant color in HSV space\n",
    "    def get_dominant_color_hsv(region):\n",
    "        # Convert the region to HSV color space\n",
    "        region_hsv = cv2.cvtColor(region, cv2.COLOR_BGR2HSV)\n",
    "        \n",
    "        # Filter out black pixels\n",
    "        non_black_pixels = (region_hsv[..., 2] != 0)\n",
    "        region_without_black = region_hsv[non_black_pixels]\n",
    "\n",
    "        # Calculate the mean color in HSV space\n",
    "        dominant_color_hsv = np.mean(region_without_black, axis=0)\n",
    "        \n",
    "        return dominant_color_hsv\n",
    "    \n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    result_list = []\n",
    "    for filename in os.listdir(input_directory):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            \n",
    "            # Read and process image\n",
    "            img_path = os.path.join(input_directory, filename)\n",
    "            img = Image.open(img_path)\n",
    "            height, width = img.size\n",
    "            resized_img = img.resize((256, 256))\n",
    "            transform = T.ToTensor()\n",
    "            img_tensor = transform(resized_img)\n",
    "\n",
    "            # Get mask rcnn prediction\n",
    "            with torch.no_grad():\n",
    "                pred = model([img_tensor.to(device)])\n",
    "\n",
    "            # Get mask output\n",
    "            mask = (pred[0][\"masks\"][0].cpu().detach().numpy() * 255).astype(\"uint8\").squeeze()\n",
    "\n",
    "            # Resize mask\n",
    "            resized_mask = cv2.resize(mask, (height, width))\n",
    "\n",
    "            # Convert to binary mask\n",
    "            resized_binary_mask = resized_mask > 100\n",
    "            binary_mask = mask > 100\n",
    "            # Get mask region\n",
    "            img_numpy = np.array(img)\n",
    "            binary_mask = binary_mask.astype(np.uint8)\n",
    "            resized_binary_mask = resized_binary_mask.astype(np.uint8)\n",
    "            masked_image = cv2.bitwise_and(img_numpy, img_numpy, mask=resized_binary_mask)\n",
    "            # Get dominant color info\n",
    "            dominant_color = get_dominant_color_hsv(masked_image)\n",
    "\n",
    "            # Get image moments\n",
    "            hu_moments = cv2.HuMoments(cv2.moments(binary_mask)).flatten()\n",
    "            hu_moments_normalized = min_max_normalize_hu_moments(hu_moments)\n",
    "            hu_sum = np.sum(hu_moments_normalized)\n",
    "            # Save result\n",
    "            result_list.append({\n",
    "                'filename': filename,\n",
    "                'dominant_color': dominant_color,\n",
    "                'hu_moments': hu_moments_normalized,\n",
    "                'hu_moments_sum': hu_sum,\n",
    "            })\n",
    "\n",
    "    # Detect color outliers\n",
    "    dominant_colors = np.array([entry['dominant_color'] for entry in result_list])\n",
    "    col_indices = [0, 1, 2]\n",
    "    lower_multipliers = [1.5, 1.5, 1.25]\n",
    "    upper_multipliers = [1.5, 1.5, 0]\n",
    "    color_outliers = detect_outliers(dominant_colors, col_indices, lower_multipliers, upper_multipliers)\n",
    "\n",
    "    # Mark color outliers in the result list\n",
    "    for i in range(len(result_list)):\n",
    "        result_list[i]['color_diff'] = str(color_outliers[i])\n",
    "    \n",
    "    # Detect shape outliers\n",
    "    hu_moments_idx = [entry['hu_moments_sum'] for entry in result_list]\n",
    "    shape_outliers = find_outliers_combined_iqr(hu_moments_idx)\n",
    "    \n",
    "    # Mark shape outliers in the result list\n",
    "    for i in range(len(result_list)):\n",
    "        result_list[i]['shape_diff'] = str(shape_outliers[i])\n",
    "\n",
    "    # Save result list to JSON file\n",
    "    output_directory = \"output\"  \n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    analysis_folder = os.path.join(output_directory, 'Analysis')\n",
    "    os.makedirs(analysis_folder, exist_ok=True)\n",
    "\n",
    "    for result in result_list:\n",
    "        result['dominant_color'] = result['dominant_color'].tolist()\n",
    "        filename = result['filename']\n",
    "        json_filename = os.path.join(analysis_folder, f\"{filename.split('.')[0]}.json\")\n",
    "\n",
    "        with open(json_filename, 'w') as json_file:\n",
    "            json.dump(result, json_file, indent=4)\n",
    "\n",
    "\n",
    "# Example use\n",
    "roi_directory = \"output/ROI\"\n",
    "process_images_in_directory(roi_directory, maskrcnn, device)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate YOLO segmentation prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Polygon\n",
    "def get_dominant_color_hsv(region):\n",
    "        # Convert the region to HSV color space\n",
    "        region_hsv = cv2.cvtColor(region, cv2.COLOR_BGR2HSV)\n",
    "        \n",
    "        # Filter out black pixels\n",
    "        non_black_pixels = (region_hsv[..., 2] != 0)\n",
    "        region_without_black = region_hsv[non_black_pixels]\n",
    "\n",
    "        # Calculate the mean color in HSV space\n",
    "        dominant_color_hsv = np.mean(region_without_black, axis=0)\n",
    "        \n",
    "        return dominant_color_hsv\n",
    "\n",
    "def min_max_normalize_hu_moments(hu_moments):\n",
    "    # Perform min-max normalization for a list of Hu moments\n",
    "    min_value = min(hu_moments)\n",
    "    max_value = max(hu_moments)\n",
    "\n",
    "    normalized_hu_moments = [(value - min_value) / (max_value - min_value) for value in hu_moments]\n",
    "\n",
    "    return normalized_hu_moments\n",
    "\n",
    "# Color outliers\n",
    "def detect_outliers(data, col_indices, lower_bound_multipliers, upper_bound_multipliers):\n",
    "    outliers = np.zeros(len(data), dtype=bool)\n",
    "\n",
    "    for col_index, lower_multiplier, upper_multiplier in zip(col_indices, lower_bound_multipliers, upper_bound_multipliers):\n",
    "        \n",
    "        q1 = np.percentile(data[:, col_index], 25)\n",
    "        q3 = np.percentile(data[:, col_index], 75)\n",
    "        iqr = q3 - q1\n",
    "        lower_bound = q1 - lower_multiplier * iqr\n",
    "        upper_bound = q3 + upper_multiplier * iqr\n",
    "\n",
    "        if col_index == 2:\n",
    "            # Skip upper bound comparison for data[:, 2]\n",
    "            outliers_col = (data[:, col_index] < lower_bound)\n",
    "        else:\n",
    "            # Perform both lower and upper bound comparisons for other columns\n",
    "            outliers_col = (data[:, col_index] < lower_bound) | (data[:, col_index] > upper_bound)\n",
    "\n",
    "        outliers |= outliers_col\n",
    "\n",
    "    return outliers\n",
    "\n",
    "# Shape outliers\n",
    "def find_outliers_combined_iqr(hu_moments_list):\n",
    "    outliers = np.zeros(len(hu_moments_list), dtype=bool)\n",
    "    # Calculate the Interquartile Range (IQR)\n",
    "    q1 = np.percentile(hu_moments_list, 25)\n",
    "    q3 = np.percentile(hu_moments_list, 75)\n",
    "    iqr_value = q3 - q1\n",
    "\n",
    "    # Define a multiplier to determine the outlier threshold\n",
    "    iqr_multiplier = 2.5 \n",
    "\n",
    "    # Define the lower and upper bounds for outliers\n",
    "    lower_bound = q1 - iqr_multiplier * iqr_value\n",
    "    upper_bound = q3 + iqr_multiplier * iqr_value\n",
    "\n",
    "    # Identify outliers based on the bounds\n",
    "    outliers_col = (hu_moments_list < lower_bound) | (hu_moments_list > upper_bound)\n",
    "    outliers |= outliers_col\n",
    "\n",
    "    return outliers\n",
    "\n",
    "def yolo_segment(input_directory, output_directory='output'):\n",
    "    result_list = []\n",
    "    # List all image files in the input directory\n",
    "    image_files = [f for f in os.listdir(input_directory) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))]\n",
    "\n",
    "    for image_file in image_files:\n",
    "        img_id = image_file.split('.')[0]\n",
    "        image_path = os.path.join(input_directory, image_file)\n",
    "        img = cv2.imread(image_path)\n",
    "        height, width, _ = img.shape\n",
    "        results = model_segmentation(img)\n",
    "        for r in results:\n",
    "            # Create a blank image\n",
    "            binary_mask = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "            # No mask detected\n",
    "            if not r:\n",
    "                continue\n",
    "            \n",
    "            # Get mask\n",
    "            mask = r.masks.xy\n",
    "\n",
    "            # Draw the mask on the blank image\n",
    "            for points in mask:\n",
    "                # Convert the points to integer and reshape to (num_points, 1, 2)\n",
    "                points = points.astype(int).reshape((-1, 1, 2))\n",
    "                \n",
    "                # Fill the polygon in the blank image\n",
    "                cv2.fillPoly(binary_mask, [points], color=255)\n",
    "\n",
    "            \n",
    "            # Cut mask region\n",
    "            img_numpy = np.array(img)\n",
    "            masked_image = cv2.bitwise_and(img_numpy, img_numpy, mask=binary_mask)\n",
    "            masked_image = cv2.cvtColor(masked_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Get dominant color info\n",
    "            dominant_color = get_dominant_color_hsv(masked_image)\n",
    "            \n",
    "            # Get image moments\n",
    "            hu_moments = cv2.HuMoments(cv2.moments(binary_mask)).flatten()\n",
    "            hu_moments_normalized = min_max_normalize_hu_moments(hu_moments)\n",
    "            hu_sum = np.sum(hu_moments_normalized)\n",
    "            # Save result\n",
    "            result_list.append({\n",
    "                'filename': image_file,\n",
    "                'dominant_color': dominant_color,\n",
    "                'hu_moments': hu_moments_normalized,\n",
    "                'hu_moments_sum': hu_sum,\n",
    "            })\n",
    "    # Detect color outliers\n",
    "    # Todo: compare color range instead of IQR\n",
    "    dominant_colors = np.array([entry['dominant_color'] for entry in result_list])\n",
    "    col_indices = [0, 1, 2]\n",
    "    lower_multipliers = [3, 3, 2]\n",
    "    upper_multipliers = [3, 3, 0]\n",
    "    color_outliers = detect_outliers(dominant_colors, col_indices, lower_multipliers, upper_multipliers)\n",
    "\n",
    "    # Detect shape outliers\n",
    "    hu_moments_idx = [entry['hu_moments_sum'] for entry in result_list]\n",
    "    shape_outliers = find_outliers_combined_iqr(hu_moments_idx)\n",
    "\n",
    "    # Save result list to JSON file for color outliers\n",
    "    output_directory = \"output\"  \n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    analysis_folder = os.path.join(output_directory, 'Outliers')\n",
    "    os.makedirs(analysis_folder, exist_ok=True)\n",
    "\n",
    "    for i in range(len(result_list)):\n",
    "        if color_outliers[i] or shape_outliers[i]:\n",
    "            result_list[i]['dominant_color'] = result_list[i]['dominant_color'].tolist()\n",
    "            result_list[i]['color_diff'] = str(color_outliers[i])\n",
    "            result_list[i]['shape_diff'] = str(shape_outliers[i])\n",
    "\n",
    "            filename = result_list[i]['filename']\n",
    "            json_filename = os.path.join(analysis_folder, f\"{filename.split('.')[0]}.json\")\n",
    "\n",
    "            with open(json_filename, 'w') as json_file:\n",
    "                json.dump(result_list[i], json_file, indent=4)\n",
    "        \n",
    "\n",
    "yolo_segment('output/ROI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
