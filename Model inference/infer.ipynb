{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import copy\n",
    "from torchvision import transforms as T\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YOLO model, assume that the model is in the same directory\n",
    "from ultralytics import YOLO\n",
    "model_detection = YOLO('detect.pt')\n",
    "model_segmentation = YOLO('segment.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate YOLO Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_detect(input_directory, output_directory='output', detection_threshold=0.5):\n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "    # Create \"Count\" folder in the output directory\n",
    "    count_folder = os.path.join(output_directory, 'Count')\n",
    "    os.makedirs(count_folder, exist_ok=True)\n",
    "\n",
    "    bbox_path = os.path.join(output_directory, 'detection')\n",
    "    os.makedirs(bbox_path, exist_ok=True)\n",
    "\n",
    "    roi_folder = os.path.join(output_directory, 'ROI')\n",
    "    os.makedirs(roi_folder, exist_ok=True)\n",
    "    \n",
    "    # List all image files in the input directory\n",
    "    image_files = [f for f in os.listdir(input_directory) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))]\n",
    "\n",
    "    # Loop through all images\n",
    "    for image_file in image_files:\n",
    "\n",
    "        # Read image and extract some information\n",
    "        img_id = image_file.split('.')[0] # Get image ID\n",
    "\n",
    "        # Load image\n",
    "        image_path = os.path.join(input_directory, image_file)\n",
    "        img = cv2.imread(image_path)\n",
    "\n",
    "        # Create a copy of the image for drawing bounding boxes\n",
    "        img_copy = copy.deepcopy(img)\n",
    "\n",
    "        # Generate bounding boxes\n",
    "        results = model_detection(img, conf=detection_threshold)\n",
    "\n",
    "        # Process results\n",
    "        for r in results:\n",
    "            # Extract bounding boxes in xyxy format\n",
    "            bbox_list = r.boxes.xyxy\n",
    "            count = len(bbox_list)  \n",
    "\n",
    "            for i, bbox in enumerate(bbox_list):\n",
    "                # Extract ROI\n",
    "                roi = img_copy[int(bbox[1]):int(bbox[3]), int(bbox[0]):int(bbox[2])]\n",
    "                # Save ROI\n",
    "                roi_path = os.path.join(roi_folder, f'{img_id}_{i+1}.jpg')\n",
    "                cv2.imwrite(roi_path, roi)\n",
    "                # Draw bounding boxes\n",
    "                img_detect = cv2.rectangle(img, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), (0, 0, 255), 5)\n",
    "\n",
    "            # Save image with bounding boxes\n",
    "            detect_path = os.path.join(bbox_path, f'{img_id}_with_boxes.jpg')\n",
    "            cv2.imwrite(detect_path, img_detect)\n",
    "\n",
    "        # Save count\n",
    "        count_filepath = os.path.join(count_folder, f'{img_id}.txt')\n",
    "        with open(count_filepath, 'w') as f:\n",
    "            f.write(str(count))\n",
    "\n",
    "# Example use\n",
    "yolo_detect('input')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate YOLO segmentation prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the dominant color in the image and return it in HSV space\n",
    "def get_dominant_color(region):\n",
    "        # Convert the region to HSV color space\n",
    "        region_hsv = cv2.cvtColor(region, cv2.COLOR_RGB2HSV)\n",
    "        \n",
    "        # Filter out black pixels\n",
    "        non_black_pixels = (region_hsv[..., 2] != 0)\n",
    "        region_without_black = region_hsv[non_black_pixels]\n",
    "        non_black_pixels_rgb = np.all(region != [0, 0, 0], axis=-1)\n",
    "        region_without_black_rgb = region[non_black_pixels_rgb]\n",
    "        # Calculate the mean color in HSV space\n",
    "        dominant_color_hsv = np.mean(region_without_black, axis=0)\n",
    "        dominant_color_rgb = np.mean(region_without_black_rgb, axis=0).astype(int)\n",
    "        return dominant_color_hsv, dominant_color_rgb\n",
    "\n",
    "# Min-max normalization for a list of Hu moments\n",
    "def min_max_normalize_hu_moments(hu_moments):\n",
    "    # Perform min-max normalization for a list of Hu moments\n",
    "    min_value = min(hu_moments)\n",
    "    max_value = max(hu_moments)\n",
    "\n",
    "    normalized_hu_moments = [(value - min_value) / (max_value - min_value) for value in hu_moments]\n",
    "\n",
    "    return normalized_hu_moments\n",
    "\n",
    "# Color outliers using IQR\n",
    "def detect_outliers(data, col_indices, lower_bound_multipliers, upper_bound_multipliers):\n",
    "    outliers = np.zeros(len(data), dtype=bool)\n",
    "\n",
    "    for col_index, lower_multiplier, upper_multiplier in zip(col_indices, lower_bound_multipliers, upper_bound_multipliers):\n",
    "        \n",
    "        q1 = np.percentile(data[:, col_index], 25)\n",
    "        q3 = np.percentile(data[:, col_index], 75)\n",
    "        iqr = q3 - q1\n",
    "        lower_bound = q1 - lower_multiplier * iqr\n",
    "        upper_bound = q3 + upper_multiplier * iqr\n",
    "\n",
    "        if col_index == 2:\n",
    "            # Skip upper bound comparison for data[:, 2]\n",
    "            outliers_col = (data[:, col_index] < lower_bound)\n",
    "        else:\n",
    "            # Perform both lower and upper bound comparisons for other columns\n",
    "            outliers_col = (data[:, col_index] < lower_bound) | (data[:, col_index] > upper_bound)\n",
    "\n",
    "        outliers |= outliers_col\n",
    "\n",
    "    return outliers\n",
    "\n",
    "# Shape outliers using IQR\n",
    "def find_outliers_combined_iqr(hu_moments_list):\n",
    "    outliers = np.zeros(len(hu_moments_list), dtype=bool)\n",
    "    # Calculate the Interquartile Range (IQR)\n",
    "    q1 = np.percentile(hu_moments_list, 25)\n",
    "    q3 = np.percentile(hu_moments_list, 75)\n",
    "    iqr_value = q3 - q1\n",
    "\n",
    "    # Define a multiplier to determine the outlier threshold\n",
    "    iqr_multiplier = 2.5 \n",
    "\n",
    "    # Define the lower and upper bounds for outliers\n",
    "    lower_bound = q1 - iqr_multiplier * iqr_value\n",
    "    upper_bound = q3 + iqr_multiplier * iqr_value\n",
    "\n",
    "    # Identify outliers based on the bounds\n",
    "    outliers_col = (hu_moments_list < lower_bound) | (hu_moments_list > upper_bound)\n",
    "    outliers |= outliers_col\n",
    "\n",
    "    return outliers\n",
    "\n",
    "# YOLO segmentation\n",
    "def yolo_segment(input_directory, output_directory='output'):\n",
    "    result_list = []\n",
    "    # List all image files in the input directory\n",
    "    image_files = [f for f in os.listdir(input_directory) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))]\n",
    "\n",
    "    for image_file in image_files:\n",
    "        img_id = image_file.split('.')[0]\n",
    "        image_path = os.path.join(input_directory, image_file)\n",
    "        img = cv2.imread(image_path)\n",
    "        height, width, _ = img.shape\n",
    "        results = model_segmentation(img)\n",
    "        for r in results:\n",
    "            # Create a blank image\n",
    "            binary_mask = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "            # No mask detected\n",
    "            if not r:\n",
    "                continue\n",
    "            \n",
    "            # Get mask\n",
    "            mask = r.masks.xy\n",
    "\n",
    "            # Draw the mask on the blank image\n",
    "            for points in mask:\n",
    "                # Convert the points to integer and reshape to (num_points, 1, 2)\n",
    "                points = points.astype(int).reshape((-1, 1, 2))\n",
    "                \n",
    "                # Fill the polygon in the blank image\n",
    "                cv2.fillPoly(binary_mask, [points], color=255)\n",
    "\n",
    "            \n",
    "            # Cut mask region\n",
    "            img_numpy = np.array(img)\n",
    "            masked_image = cv2.bitwise_and(img_numpy, img_numpy, mask=binary_mask)\n",
    "            masked_image_rgb = cv2.cvtColor(masked_image, cv2.COLOR_BGR2RGB)\n",
    "            # Get dominant color info\n",
    "            dominant_color_hsv, dominant_color_rgb = get_dominant_color(masked_image_rgb)\n",
    "            \n",
    "            # Get image moments\n",
    "            hu_moments = cv2.HuMoments(cv2.moments(binary_mask)).flatten()\n",
    "            hu_moments_normalized = min_max_normalize_hu_moments(hu_moments)\n",
    "            hu_sum = np.sum(hu_moments_normalized)\n",
    "            \n",
    "            # Save result\n",
    "            result_list.append({\n",
    "                'filename': image_file,\n",
    "                'dominant_color_hsv': dominant_color_hsv,\n",
    "                'dominant_color_rgb': dominant_color_rgb,\n",
    "                'hu_moments': hu_moments_normalized,\n",
    "                'hu_moments_sum': hu_sum,\n",
    "            })\n",
    "\n",
    "    # Detect color outliers\n",
    "    dominant_colors = np.array([entry['dominant_color_hsv'] for entry in result_list])\n",
    "    col_indices = [0, 1, 2]\n",
    "    lower_multipliers = [3, 3, 2]\n",
    "    upper_multipliers = [3, 3, 0]\n",
    "    color_outliers = detect_outliers(dominant_colors, col_indices, lower_multipliers, upper_multipliers)\n",
    "\n",
    "    # Detect shape outliers\n",
    "    hu_moments_idx = [entry['hu_moments_sum'] for entry in result_list]\n",
    "    shape_outliers = find_outliers_combined_iqr(hu_moments_idx)\n",
    "\n",
    "    # Save result list to JSON file for color outliers\n",
    "    output_directory = \"output\"  \n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    analysis_folder = os.path.join(output_directory, 'Outliers')\n",
    "    os.makedirs(analysis_folder, exist_ok=True)\n",
    "\n",
    "    for i in range(len(result_list)):\n",
    "        if color_outliers[i] or shape_outliers[i]:\n",
    "            result_list[i]['dominant_color_hsv'] = result_list[i]['dominant_color_hsv'].tolist()\n",
    "            result_list[i]['dominant_color_rgb'] = result_list[i]['dominant_color_rgb'].tolist()\n",
    "            result_list[i]['color_diff'] = str(color_outliers[i])\n",
    "            result_list[i]['shape_diff'] = str(shape_outliers[i])\n",
    "\n",
    "            filename = result_list[i]['filename']\n",
    "            json_filename = os.path.join(analysis_folder, f\"{filename.split('.')[0]}.json\")\n",
    "\n",
    "            with open(json_filename, 'w') as json_file:\n",
    "                json.dump(result_list[i], json_file, indent=4)\n",
    "        \n",
    "# Example use\n",
    "yolo_segment('output/ROI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
