{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "# Faster RCNN prediction\n",
    "# Extract ROI\n",
    "# Mask RCNN prediction\n",
    "# Extract color information\n",
    "# 3D scatter plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import re\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from torchvision import transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cressensia/opt/anaconda3/envs/myenv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/cressensia/opt/anaconda3/envs/myenv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "# Load faster rcnn model\n",
    "fasterrcnn = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "in_features = fasterrcnn.roi_heads.box_predictor.cls_score.in_features\n",
    "fasterrcnn.roi_heads.box_predictor = FastRCNNPredictor(in_features, 2)\n",
    "fasterrcnn.load_state_dict(torch.load(\"fasterrcnn_phase1.pth\", map_location=device))\n",
    "fasterrcnn = fasterrcnn.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Faster RCNN Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate faster RCNN prediction\n",
    "def predict(model, images):\n",
    "    model.eval()\n",
    "    images = list(image.to(device) for image in images)\n",
    "    outputs = model(images)\n",
    "    return outputs\n",
    "\n",
    "# Draw bounding box on processed image (1024x1024)\n",
    "def draw_boxes_on_image(boxes, images):\n",
    "    for box in boxes:\n",
    "        cv2.rectangle(images,\n",
    "                      (box[0], box[1]),\n",
    "                      (box[2], box[3]),\n",
    "                      (220, 0, 0), 3)\n",
    "    return images\n",
    "\n",
    "# Extract maize tassel image from bounding box\n",
    "def extract_roi(img, img_id, boxes, output_directory):\n",
    "    roi_folder = os.path.join(output_directory, 'ROI')\n",
    "    os.makedirs(roi_folder, exist_ok=True)\n",
    "    for i, box in enumerate(boxes):\n",
    "        x1 = box[0]\n",
    "        y1 = box[1]\n",
    "        x2 = box[2]\n",
    "        y2 = box[3]\n",
    "        # Extract the region of interest (ROI)\n",
    "        roi = img[y1:y2, x1:x2]\n",
    "\n",
    "        # Save the ROI\n",
    "        output_path = os.path.join(roi_folder, f'{img_id}_{i+1}.jpg')\n",
    "        cv2.imwrite(output_path, roi)\n",
    "\n",
    "# Resize bounding box coordinates to original image size\n",
    "def resize_bbox(original_width, original_height, boxes):\n",
    "    for box in boxes:\n",
    "\n",
    "        # Extract coordinates\n",
    "        x1 = box[0]\n",
    "        y1 = box[1]\n",
    "        x2 = box[2]\n",
    "        y2 = box[3]\n",
    "\n",
    "        # Calculate scale factor\n",
    "        width_scale = original_width / 1024\n",
    "        height_scale = original_height / 1024\n",
    "\n",
    "        # Calculate new coordinates\n",
    "        resized_x1 = int(x1 * width_scale)\n",
    "        resized_y1 = int(y1 * height_scale)\n",
    "        resized_x2 = int(x2 * width_scale)\n",
    "        resized_y2 = int(y2 * height_scale)\n",
    "\n",
    "        # Assign new coordinates\n",
    "        box[0] = resized_x1\n",
    "        box[1] = resized_y1\n",
    "        box[2] = resized_x2\n",
    "        box[3] = resized_y2\n",
    "        \n",
    "    return boxes\n",
    "\n",
    "# faster rcnn inference\n",
    "def process_images_and_predict(input_directory, output_directory='output', detection_threshold=0.6):\n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "    # Create \"Count\" folder in the output directory\n",
    "    count_folder = os.path.join(output_directory, 'Count')\n",
    "    os.makedirs(count_folder, exist_ok=True)\n",
    "\n",
    "    # List all image files in the input directory\n",
    "    image_files = [f for f in os.listdir(input_directory) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))]\n",
    "\n",
    "    for img_name in image_files:\n",
    "        \n",
    "        # Read and preprocess image\n",
    "        img_id = img_name.split('.')[0]\n",
    "        image_path = os.path.join(input_directory, img_name)\n",
    "        img = cv2.imread(image_path)\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        img_res = cv2.resize(img_rgb, (1024, 1024), cv2.INTER_AREA)\n",
    "        img_res /= 255.0\n",
    "\n",
    "        # Generate Faster RCNN prediction\n",
    "        output = predict(fasterrcnn, [torch.tensor(img_res, dtype=torch.float32).permute(2, 0, 1).to(device)])\n",
    "        prediction_boxes = output[0]['boxes'].data.cpu().numpy()\n",
    "        scores = output[0]['scores'].data.cpu().numpy()\n",
    "        count = len(prediction_boxes)\n",
    "        # Filter boxes based on detection threshold\n",
    "        prediction_boxes = prediction_boxes[scores >= detection_threshold].astype(np.int32)\n",
    "\n",
    "        # Resize bounding boxes to original image size\n",
    "        prediction_boxes_resized = resize_bbox(img.shape[1], img.shape[0], prediction_boxes)\n",
    "\n",
    "        # Draw bounding box on image and save\n",
    "        img_with_boxes = draw_boxes_on_image(prediction_boxes_resized, img_rgb)\n",
    "        bbox_path = os.path.join(output_directory, 'detection')\n",
    "        os.makedirs(bbox_path, exist_ok=True)\n",
    "        output_path = os.path.join(bbox_path, f'{img_id}_with_boxes.jpg')\n",
    "        cv2.imwrite(output_path, cv2.cvtColor(img_with_boxes, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        # Run extract ROI for image\n",
    "        extract_roi(img, img_id, prediction_boxes_resized, output_directory)\n",
    "\n",
    "        # Save count to text file in \"Count\" folder\n",
    "        count_filepath = os.path.join(count_folder, f'{img_id}.txt')\n",
    "        with open(count_filepath, 'w') as f:\n",
    "            f.write(str(count))\n",
    "\n",
    "# Call the function with the input directory\n",
    "input_directory = 'input'\n",
    "process_images_and_predict(input_directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
