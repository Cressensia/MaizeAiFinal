{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToPILImage\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image, ImageChops, ImageDraw\n",
    "import os\n",
    "import json\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, OneCycleLR\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 4 # 3 diseases rn + healthy class\n",
    "\n",
    "#class names must be same as roboflow (i think category_id)\n",
    "category_to_disease = {\n",
    "    1: \"healthy\",\n",
    "    2: \"maize-blight\",\n",
    "    3: \"maize-common-rust\",\n",
    "    4: \"maize-leaf-spot\"\n",
    "    # ... and so on for each category_id\n",
    "}\n",
    "\n",
    "#mapping dict\n",
    "disease_to_id = {\n",
    "    \"healthy\": 0,\n",
    "    \"maize-blight\": 1,\n",
    "    \"maize-common-rust\": 2,\n",
    "    \"maize-leaf-spot\": 3\n",
    "\n",
    "    # Add other diseases here if needed\n",
    "}\n",
    "\n",
    "# Inverse mapping of disease_to_id\n",
    "disease_mapping = {v: k for k, v in disease_to_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        '''\n",
    "        # Encoder (Contracting Path)\n",
    "        self.enc_conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.enc_bn1 = nn.BatchNorm2d(32)\n",
    "        self.enc_conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.enc_bn2 = nn.BatchNorm2d(32)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Middle part (Bottleneck)\n",
    "        self.middle_conv1 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.middle_bn1 = nn.BatchNorm2d(64)\n",
    "        self.middle_conv2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.middle_bn2 = nn.BatchNorm2d(64)\n",
    "\n",
    "        # Decoder (Expansive Path)\n",
    "        self.up_conv1 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2)\n",
    "        self.dec_conv1 = nn.Conv2d(64, 32, kernel_size=3, padding=1)\n",
    "        self.dec_bn1 = nn.BatchNorm2d(32)\n",
    "        self.dec_conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.dec_bn2 = nn.BatchNorm2d(32)\n",
    "\n",
    "        # Dropout for regularization - Adjusted dropout rate\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "        # Final convolution\n",
    "        self.final_conv = nn.Conv2d(32, 1, kernel_size=1)\n",
    "\n",
    "        # Classification layers\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc1 = nn.Linear(64, 64)\n",
    "        self.fc2 = nn.Linear(64, num_classes)\n",
    "        \n",
    "        '''\n",
    "        #reduced filters - slightly faster\n",
    "        \n",
    "        # Encoder\n",
    "        self.enc_conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.enc_bn1 = nn.BatchNorm2d(16)\n",
    "        self.enc_conv2 = nn.Conv2d(16, 16, kernel_size=3, padding=1)\n",
    "        self.enc_bn2 = nn.BatchNorm2d(16)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Middle part (Bottleneck)\n",
    "        self.middle_conv1 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.middle_bn1 = nn.BatchNorm2d(32)\n",
    "        self.middle_conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.middle_bn2 = nn.BatchNorm2d(32)\n",
    "\n",
    "        # Decoder\n",
    "        self.up_conv1 = nn.ConvTranspose2d(32, 16, kernel_size=2, stride=2)\n",
    "        self.dec_conv1 = nn.Conv2d(32, 16, kernel_size=3, padding=1)\n",
    "        self.dec_bn1 = nn.BatchNorm2d(16)\n",
    "        self.dec_conv2 = nn.Conv2d(16, 16, kernel_size=3, padding=1)\n",
    "        self.dec_bn2 = nn.BatchNorm2d(16)\n",
    "\n",
    "        # Keep the dropout rate the same for now\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "        # Final convolution\n",
    "        self.final_conv = nn.Conv2d(16, 1, kernel_size=1)\n",
    "\n",
    "        # Classification layers - Adjusted to match the new filter sizes\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc1 = nn.Linear(32, 32)\n",
    "        self.fc2 = nn.Linear(32, num_classes)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        e1 = F.leaky_relu(self.enc_bn1(self.enc_conv1(x)))\n",
    "        e1 = F.leaky_relu(self.enc_bn2(self.enc_conv2(e1)))\n",
    "        p1 = self.pool1(e1)\n",
    "\n",
    "        # Middle part\n",
    "        m = F.leaky_relu(self.middle_bn1(self.middle_conv1(p1)))\n",
    "        m = F.leaky_relu(self.middle_bn2(self.middle_conv2(m)))\n",
    "\n",
    "        # Decoder\n",
    "        d1 = self.up_conv1(m)\n",
    "        # Resize d1 to match the size of p1 before concatenation\n",
    "        d1 = F.interpolate(d1, size=(p1.size(2), p1.size(3)), mode='bilinear', align_corners=True)\n",
    "        d1 = torch.cat((p1, d1), dim=1)\n",
    "        d1 = F.leaky_relu(self.dec_bn1(self.dec_conv1(d1)))\n",
    "        d1 = F.leaky_relu(self.dec_bn2(self.dec_conv2(d1)))\n",
    "        d1 = self.dropout(d1)\n",
    "\n",
    "        out = self.final_conv(d1)\n",
    "\n",
    "        # Resize the output to match the input size if necessary\n",
    "        out = F.interpolate(out, size=(256, 256), mode='bilinear', align_corners=True)\n",
    "\n",
    "        # Classification branch\n",
    "        class_features = self.global_avg_pool(m)\n",
    "        class_features = class_features.view(class_features.size(0), -1)\n",
    "        class_features = F.relu(self.fc1(class_features))\n",
    "        class_output = self.fc2(class_features)\n",
    "\n",
    "        return out, class_output\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "                nn.init.kaiming_uniform_(m.weight, nonlinearity='leaky_relu')  # He initialization\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "\n",
    "# Function to predict the segmentation mask\n",
    "def predict(img_tensor, model):\n",
    "    # Ensure the model is in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Assuming img_tensor is already preprocessed and ready for model input\n",
    "    # If img_tensor is a single image, add a batch dimension\n",
    "    if len(img_tensor.shape) == 3:\n",
    "        img_tensor = img_tensor.unsqueeze(0)\n",
    "\n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        mask_output, class_output = model(img_tensor)\n",
    "\n",
    "        # Process outputs\n",
    "        _, predicted_class = torch.max(class_output, 1)\n",
    "        predicted_disease = predicted_class.item()\n",
    "        predicted_mask = torch.sigmoid(mask_output[0]).float()  # First item in batch\n",
    "        predicted_mask = (predicted_mask > 0.5).float()  # Binarize mask\n",
    "\n",
    "    return predicted_mask.cpu(), predicted_disease\n",
    "\n",
    "# Function to create prediction image\n",
    "def create_prediction_image(img_tensor, predicted_mask, disease_name):\n",
    "    # Convert tensor to PIL image\n",
    "    img_pil = ToPILImage()(img_tensor.cpu()).convert(\"RGB\")\n",
    "\n",
    "    # Only add mask if disease is detected\n",
    "    if disease_name != \"healthy\":\n",
    "        mask_pil = ToPILImage()(predicted_mask.cpu().squeeze()).convert(\"L\")\n",
    "        mask_pil = mask_pil.resize(img_pil.size)\n",
    "        mask_color = Image.new(\"RGB\", mask_pil.size, (255, 0, 0))\n",
    "        mask_pil_colored = ImageChops.multiply(mask_color, mask_pil.convert(\"RGB\"))\n",
    "        img_with_mask = ImageChops.add(img_pil, mask_pil_colored)\n",
    "        composite_image = Image.new('RGB', (img_pil.width * 2, img_pil.height))\n",
    "        composite_image.paste(img_pil, (0, 0))\n",
    "        composite_image.paste(img_with_mask, (img_pil.width, 0))\n",
    "    else:\n",
    "        composite_image = img_pil\n",
    "\n",
    "    # Add text to the composite image\n",
    "    draw = ImageDraw.Draw(composite_image)\n",
    "    if disease_name != \"healthy\":\n",
    "        draw.text((10, 10), \"Original Image:\", fill=\"black\")\n",
    "        draw.text((img_pil.width + 10, 10), f\"Predicted Disease: {disease_name}\", fill=\"black\")\n",
    "    else:\n",
    "        draw.text((10, 10), \"No Mask for Healthy Class. Leaf Inputted is Healthy.\", fill=\"white\")\n",
    "\n",
    "    return composite_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Unet model\n",
    "device = torch.device('cpu')\n",
    "model = UNet().to(device)\n",
    "model.load_state_dict(torch.load(\"unet_best.pth\", map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image, ImageDraw\n",
    "from torchvision.transforms.functional import to_tensor, to_pil_image\n",
    "def process_image_and_generate_prediction(input_image_path, output_dir='output', model=None):\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Load image\n",
    "    img = Image.open(input_image_path).convert('RGB')\n",
    "    img_tensor = to_tensor(img)\n",
    "\n",
    "    # Generate model prediction\n",
    "    predicted_mask, predicted_disease = predict(img_tensor, model)\n",
    "\n",
    "    # Map predicted disease index to disease name\n",
    "    disease_mapping = {0: \"healthy\", 1: \"maize-blight\", 2: \"maize-common-rust\", 3: \"maize-leaf-spot\"}\n",
    "    disease_name = disease_mapping.get(predicted_disease, \"Unknown\")\n",
    "\n",
    "    # Create prediction image\n",
    "    prediction_image = create_prediction_image(img_tensor, predicted_mask, disease_name)\n",
    "\n",
    "    # Save prediction image (prediction_<input image name>)\n",
    "    output_path = os.path.join(output_dir, f\"prediction_{os.path.basename(input_image_path)}\")\n",
    "    prediction_image.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example use\n",
    "process_image_and_generate_prediction('test.jpg', model=model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
